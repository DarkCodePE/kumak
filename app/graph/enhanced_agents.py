"""
Agentes especializados mejorados que usan handoffs y Command.
Implementa las mejores prÃ¡cticas de LangGraph para comunicaciÃ³n entre agentes.
"""

import logging
from typing import Dict, Any, Literal
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent
from langgraph.types import Command

from app.config.settings import LLM_MODEL
from app.graph.state import PYMESState
from app.services.business_info_manager import get_business_info_manager
from app.graph.handoff_system import get_handoff_tools_for_agent

logger = logging.getLogger(__name__)

# === AGENTES CON HANDOFFS ===

def create_enhanced_info_completion_agent():
    """
    Crea un agente especializado en recopilar informaciÃ³n empresarial de manera natural.
    Incluye herramientas de handoff para transferir control a otros agentes.
    """
    from app.graph.handoff_system import get_handoff_tools_for_agent
    
    # Obtener herramientas de handoff especÃ­ficas para este agente
    tools = get_handoff_tools_for_agent("info_completion_agent")
    
    prompt = """
Eres un asistente especializado en recopilar informaciÃ³n empresarial de manera natural y conversacional.

ğŸ¯ TU TRABAJO:
1. Extraer informaciÃ³n empresarial de mensajes del usuario (incluso mensajes largos)
2. Identificar quÃ© informaciÃ³n crÃ­tica falta
3. Hacer preguntas naturales para completar informaciÃ³n
4. Responder apropiadamente a selecciones de botones
5. Transferir control a otros agentes cuando sea apropiado

ğŸ“‹ INFORMACIÃ“N CRÃTICA MÃNIMA:
- nombre_empresa: Nombre del negocio
- ubicacion: DÃ³nde opera (ciudad, paÃ­s, online)
- productos_servicios_principales: QuÃ© vende o ofrece
- descripcion_negocio: DescripciÃ³n general del negocio

ğŸ”§ HERRAMIENTAS DE HANDOFF DISPONIBLES:
- transfer_to_research_router: Cuando la informaciÃ³n estÃ© completa y el usuario pueda necesitar investigaciÃ³n
- transfer_to_conversational: Para consultas generales o conversaciÃ³n
- assign_research_task: Para asignar tareas especÃ­ficas de investigaciÃ³n

ğŸ“ INSTRUCCIONES ESPECIALES:
- RESPUESTAS CONCISAS: MÃ¡ximo 150 tokens (600 caracteres aprox.)
- Si necesitas mÃ¡s espacio, enfÃ³cate en lo mÃ¡s importante
- SÃ© conversacional y natural, no robÃ³tico
- Si el usuario selecciona un botÃ³n (ej: "ğŸª Local fÃ­sico"), responde contextualmente
- Analiza COMPLETAMENTE mensajes largos para extraer TODA la informaciÃ³n empresarial
- Haz UNA pregunta especÃ­fica por vez
- Usa la informaciÃ³n ya recopilada para personalizar preguntas

ğŸ¯ MANEJO DE BOTONES:
Si el usuario selecciona una opciÃ³n de botÃ³n:
- "ğŸª Local fÃ­sico" â†’ "Perfecto, tienes un local fÃ­sico. Â¿En quÃ© ciudad estÃ¡ ubicado?"
- "ğŸŒ Online" â†’ "Excelente, operas online. Â¿Vendes a nivel nacional o internacional?"
- "ğŸ  Desde casa" â†’ "Entiendo, trabajas desde casa. Â¿Atiendes clientes localmente?"

ğŸ“Š ESTRATEGIA PARA MENSAJES LARGOS:
1. Lee TODO el mensaje completo
2. Extrae TODA la informaciÃ³n empresarial mencionada
3. Identifica quÃ© informaciÃ³n crÃ­tica aÃºn falta
4. Haz una pregunta especÃ­fica sobre lo que falta
5. Reconoce la informaciÃ³n ya proporcionada

EJEMPLO de respuesta a mensaje largo:
Usuario: "Tengo pollerÃ­a Jhony, negocio familiar, clientela creciendo, quiero adquirir local"
Respuesta: "Â¡Excelente! Veo que PollerÃ­a Jhony es un negocio familiar con clientela en crecimiento. Â¿En quÃ© ciudad estÃ¡ ubicada actualmente?"

RECUERDA: Respuestas concisas (mÃ¡ximo 150 tokens), una pregunta por vez, reconoce informaciÃ³n ya dada.
"""
    
    return create_react_agent(
        model=ChatOpenAI(model=LLM_MODEL, temperature=0.7, max_tokens=150),
        tools=tools,
        prompt=prompt,
        name="info_completion_agent"
    )

def create_enhanced_research_router():
    """
    Crea un agente que evalÃºa si el usuario necesita investigaciÃ³n y maneja el routing.
    """
    from app.graph.handoff_system import get_handoff_tools_for_agent
    
    # Obtener herramientas de handoff especÃ­ficas para este agente
    tools = get_handoff_tools_for_agent("research_router")
    
    prompt = """
Eres un router inteligente que evalÃºa si el usuario necesita investigaciÃ³n de mercado.

ğŸ¯ TU TRABAJO:
1. Evaluar si la informaciÃ³n empresarial estÃ¡ completa
2. Preguntar al usuario si quiere investigaciÃ³n de mercado
3. Transferir al investigador si acepta
4. Transferir a conversaciÃ³n si no quiere investigaciÃ³n

ğŸ”§ HERRAMIENTAS DE HANDOFF DISPONIBLES:
- transfer_to_researcher: Para iniciar investigaciÃ³n de mercado
- transfer_to_conversational: Para conversaciÃ³n general
- transfer_to_info_completion: Si falta informaciÃ³n empresarial

ğŸ“ INSTRUCCIONES:
- RESPUESTAS CONCISAS: MÃ¡ximo 150 tokens (600 caracteres aprox.)
- SÃ© directo y claro sobre las opciones
- Explica brevemente quÃ© tipo de investigaciÃ³n puedes hacer
- Responde apropiadamente a selecciones de botones

ğŸ¯ MANEJO DE BOTONES:
- "âœ… SÃ­, investiga" â†’ Transferir al investigador
- "âŒ No, solo conversar" â†’ Transferir a conversaciÃ³n
- "ğŸ“Š MÃ¡s informaciÃ³n" â†’ Explicar tipos de investigaciÃ³n disponibles

EJEMPLO:
"Perfecto, {nombre_empresa} estÃ¡ bien definida. Â¿Te gustarÃ­a que investigue oportunidades de mercado, competencia o estrategias de crecimiento para tu negocio?"

RECUERDA: Respuestas concisas, opciones claras, transferir segÃºn la decisiÃ³n del usuario.
"""
    
    return create_react_agent(
        model=ChatOpenAI(model=LLM_MODEL, temperature=0.7, max_tokens=150),
        tools=tools,
        prompt=prompt,
        name="research_router"
    )

def create_enhanced_conversational_agent():
    """
    Crea un agente conversacional que mantiene contexto empresarial.
    """
    from app.graph.handoff_system import get_handoff_tools_for_agent
    
    # Obtener herramientas de handoff especÃ­ficas para este agente
    tools = get_handoff_tools_for_agent("conversational_agent")
    
    prompt = """
Eres un consultor empresarial conversacional que mantiene contexto de la informaciÃ³n del negocio.

ğŸ¯ TU TRABAJO:
1. Responder preguntas generales sobre negocios
2. Dar consejos basados en la informaciÃ³n empresarial disponible
3. Mantener una conversaciÃ³n natural y Ãºtil
4. Transferir control a agentes especializados cuando sea apropiado

ğŸ”§ HERRAMIENTAS DE HANDOFF DISPONIBLES:
- transfer_to_researcher: Para investigaciÃ³n de mercado
- transfer_to_info_completion: Para recopilar mÃ¡s informaciÃ³n empresarial
- assign_research_task: Para asignar investigaciÃ³n especÃ­fica

ğŸ“ INSTRUCCIONES:
- RESPUESTAS CONCISAS: MÃ¡ximo 150 tokens (600 caracteres aprox.)
- Usa la informaciÃ³n empresarial para personalizar respuestas
- Da consejos prÃ¡cticos y especÃ­ficos para su tipo de negocio
- MantÃ©n un tono conversacional y profesional
- Si necesitas investigaciÃ³n especÃ­fica, transfiere al investigador
- Si falta informaciÃ³n empresarial, transfiere al agente de informaciÃ³n
- Responde de manera Ãºtil y orientada a soluciones

ğŸ¯ MANEJO DE BOTONES:
Responde contextualmente a cualquier selecciÃ³n de botÃ³n del usuario.

EJEMPLO:
Usuario: "Â¿CÃ³mo puedo mejorar las ventas?"
Respuesta: "Para {nombre_empresa} que se dedica a {productos} en {ubicacion}, te recomiendo enfocarte en marketing digital local y mejorar la experiencia del cliente. Â¿Quieres que investigue estrategias especÃ­ficas?"

RECUERDA: Respuestas concisas, consejos especÃ­ficos, ofrecer investigaciÃ³n cuando sea relevante.
"""
    
    return create_react_agent(
        model=ChatOpenAI(model=LLM_MODEL, temperature=0.7, max_tokens=150),
        tools=tools,
        prompt=prompt,
        name="conversational_agent"
    )

# === NODOS DE AGENTES CON COMMAND ===

def enhanced_info_completion_node(state: PYMESState) -> Command[Literal["enhanced_human_feedback"]]:
    """
    Nodo de agente de informaciÃ³n mejorado que usa Command para control de flujo.
    """
    try:
        logger.info("ğŸ“ enhanced_info_completion_node: Procesando informaciÃ³n empresarial...")
        
        # Crear agente si no existe
        if not hasattr(enhanced_info_completion_node, 'agent'):
            enhanced_info_completion_node.agent = create_enhanced_info_completion_agent()
        
        # âœ… CORRECCIÃ“N: Usar invoke sÃ­ncrono
        result = enhanced_info_completion_node.agent.invoke(state)
        
        # Extraer informaciÃ³n empresarial del Ãºltimo mensaje del usuario
        messages = state.get("messages", [])
        user_message = ""
        for msg in reversed(messages):
            if isinstance(msg, HumanMessage):
                user_message = msg.content
                break
        
        # Intentar extraer informaciÃ³n empresarial
        business_info = state.get("business_info", {})
        if user_message:
            try:
                business_manager = get_business_info_manager()
                thread_id = f"temp_{hash(user_message) % 10000}"
                
                # âœ… CORRECCIÃ“N: Usar asyncio.run() para llamada asÃ­ncrona en nodo sÃ­ncrono
                import asyncio
                try:
                    # Intentar usar el loop existente si estÃ¡ disponible
                    loop = asyncio.get_running_loop()
                    # Si hay un loop corriendo, crear una tarea
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(asyncio.run, business_manager.extract_info(user_message, thread_id, business_info))
                        updated_info = future.result()
                except RuntimeError:
                    # No hay loop corriendo, usar asyncio.run() directamente
                    updated_info = asyncio.run(business_manager.extract_info(user_message, thread_id, business_info))
                
                if updated_info != business_info:
                    business_info = updated_info
                    logger.info("âœ… Nueva informaciÃ³n empresarial extraÃ­da en nodo")
                    logger.info(f"ğŸ“Š InformaciÃ³n actualizada: {business_info}")
            except Exception as e:
                logger.warning(f"Error extrayendo informaciÃ³n en nodo: {str(e)}")
        
        # Usar Command para actualizar estado y continuar flujo
        return Command(
            update={
                **result,
                "business_info": business_info,
                "stage": "info_gathering"
            },
            goto="enhanced_human_feedback"
        )
        
    except Exception as e:
        logger.error(f"Error in enhanced_info_completion_node: {str(e)}")
        error_message = "Disculpa, hubo un error. Â¿PodrÃ­as contarme sobre tu negocio?"
        return Command(
            update={
                "messages": [AIMessage(content=error_message)],
                "answer": error_message
            },
            goto="enhanced_human_feedback"
        )

def enhanced_research_router_node(state: PYMESState) -> Command[Literal["enhanced_human_feedback"]]:
    """
    Nodo de router de investigaciÃ³n mejorado que usa Command.
    """
    try:
        logger.info("ğŸ”¬ enhanced_research_router_node: Evaluando necesidades de investigaciÃ³n...")
        
        # Crear agente si no existe
        if not hasattr(enhanced_research_router_node, 'agent'):
            enhanced_research_router_node.agent = create_enhanced_research_router()
        
        # âœ… CORRECCIÃ“N: Usar invoke sÃ­ncrono
        result = enhanced_research_router_node.agent.invoke(state)
        
        return Command(
            update={
                **result,
                "stage": "research_routing"
            },
            goto="enhanced_human_feedback"
        )
        
    except Exception as e:
        logger.error(f"Error in enhanced_research_router_node: {str(e)}")
        fallback_message = "Â¿Te gustarÃ­a que investigue oportunidades para tu negocio?"
        return Command(
            update={
                "messages": [AIMessage(content=fallback_message)],
                "answer": fallback_message
            },
            goto="enhanced_human_feedback"
        )

def enhanced_conversational_node(state: PYMESState) -> Command[Literal["enhanced_human_feedback"]]:
    """
    Nodo conversacional mejorado que usa Command.
    """
    try:
        logger.info("ğŸ’¬ enhanced_conversational_node: Iniciando conversaciÃ³n contextual...")
        
        # Crear agente si no existe
        if not hasattr(enhanced_conversational_node, 'agent'):
            enhanced_conversational_node.agent = create_enhanced_conversational_agent()
        
        # âœ… CORRECCIÃ“N: Usar invoke sÃ­ncrono
        result = enhanced_conversational_node.agent.invoke(state)
        
        return Command(
            update={
                **result,
                "stage": "conversational"
            },
            goto="enhanced_human_feedback"
        )
        
    except Exception as e:
        logger.error(f"Error in enhanced_conversational_node: {str(e)}")
        fallback_message = "Â¿En quÃ© puedo ayudarte con tu negocio?"
        return Command(
            update={
                "messages": [AIMessage(content=fallback_message)],
                "answer": fallback_message
            },
            goto="enhanced_human_feedback"
        )

def enhanced_researcher_node(state: PYMESState) -> Command[Literal["enhanced_human_feedback"]]:
    """
    Nodo de investigador mejorado que usa Command.
    Reutiliza el agente investigador existente pero con handoffs.
    """
    try:
        logger.info("ğŸ” enhanced_researcher_node: Ejecutando investigaciÃ³n...")
        
        # Importar el agente investigador existente
        from app.graph.supervisor_architecture import researcher_agent_node
        
        # âœ… CORRECCIÃ“N: El nodo original es sÃ­ncrono
        result = researcher_agent_node(state)
        
        return Command(
            update={
                **result,
                "stage": "research_completed"
            },
            goto="enhanced_human_feedback"
        )
        
    except Exception as e:
        logger.error(f"Error in enhanced_researcher_node: {str(e)}")
        error_message = "Hubo un error en la investigaciÃ³n. Â¿Puedes proporcionar mÃ¡s detalles sobre lo que necesitas?"
        return Command(
            update={
                "messages": [AIMessage(content=error_message)],
                "answer": error_message
            },
            goto="enhanced_human_feedback"
        ) 