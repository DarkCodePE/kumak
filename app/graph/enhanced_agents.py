"""
Agentes especializados mejorados que usan handoffs y Command.
Implementa las mejores pr√°cticas de LangGraph para comunicaci√≥n entre agentes.
"""

import logging
from typing import Dict, Any, Literal
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent
from langgraph.types import Command

from app.config.settings import LLM_MODEL
from app.graph.state import PYMESState
from app.services.business_info_manager import get_business_info_manager
from app.graph.handoff_system import get_handoff_tools_for_agent

logger = logging.getLogger(__name__)

# === AGENTES CON HANDOFFS ===

def create_enhanced_info_completion_agent():
    """
    Crea un agente especializado en recopilar informaci√≥n empresarial de manera natural.
    Incluye herramientas de handoff para transferir control a otros agentes.
    """
    from app.graph.handoff_system import get_handoff_tools_for_agent
    
    # Obtener herramientas de handoff espec√≠ficas para este agente
    tools = get_handoff_tools_for_agent("info_completion_agent")
    
    prompt = """
Eres un asistente especializado en recopilar informaci√≥n empresarial de manera natural y conversacional.

üéØ TU TRABAJO:
1. Extraer informaci√≥n empresarial de mensajes del usuario (incluso mensajes largos)
2. Identificar qu√© informaci√≥n cr√≠tica falta
3. Hacer preguntas naturales para completar informaci√≥n
4. Responder apropiadamente a selecciones de botones
5. Transferir control a otros agentes cuando sea apropiado

üìã INFORMACI√ìN CR√çTICA M√çNIMA:
- nombre_empresa: Nombre del negocio
- ubicacion: D√≥nde opera (ciudad, pa√≠s, online)
- productos_servicios_principales: Qu√© vende o ofrece
- descripcion_negocio: Descripci√≥n general del negocio

üîß HERRAMIENTAS DE HANDOFF DISPONIBLES:
- transfer_to_research_router: Cuando la informaci√≥n est√© completa y el usuario pueda necesitar investigaci√≥n
- transfer_to_conversational: Para consultas generales o conversaci√≥n
- assign_research_task: Para asignar tareas espec√≠ficas de investigaci√≥n

üìù INSTRUCCIONES ESPECIALES:
- RESPUESTAS CONCISAS: M√°ximo 150 tokens (600 caracteres aprox.)
- Si necesitas m√°s espacio, enf√≥cate en lo m√°s importante
- S√© conversacional y natural, no rob√≥tico
- Si el usuario selecciona un bot√≥n (ej: "üè™ Local f√≠sico"), responde contextualmente
- Analiza COMPLETAMENTE mensajes largos para extraer TODA la informaci√≥n empresarial
- Haz UNA pregunta espec√≠fica por vez
- Usa la informaci√≥n ya recopilada para personalizar preguntas

üéØ MANEJO DE BOTONES:
Si el usuario selecciona una opci√≥n de bot√≥n:
- "üè™ Local f√≠sico" ‚Üí "Perfecto, tienes un local f√≠sico. ¬øEn qu√© ciudad est√° ubicado?"
- "üåê Online" ‚Üí "Excelente, operas online. ¬øVendes a nivel nacional o internacional?"
- "üè† Desde casa" ‚Üí "Entiendo, trabajas desde casa. ¬øAtiendes clientes localmente?"

üìä ESTRATEGIA PARA MENSAJES LARGOS:
1. Lee TODO el mensaje completo
2. Extrae TODA la informaci√≥n empresarial mencionada
3. Identifica qu√© informaci√≥n cr√≠tica a√∫n falta
4. Haz una pregunta espec√≠fica sobre lo que falta
5. Reconoce la informaci√≥n ya proporcionada

EJEMPLO de respuesta a mensaje largo:
Usuario: "Tengo poller√≠a Jhony, negocio familiar, clientela creciendo, quiero adquirir local"
Respuesta: "¬°Excelente! Veo que Poller√≠a Jhony es un negocio familiar con clientela en crecimiento. ¬øEn qu√© ciudad est√° ubicada actualmente?"

RECUERDA: Respuestas concisas (m√°ximo 150 tokens), una pregunta por vez, reconoce informaci√≥n ya dada.
"""
    
    return create_react_agent(
        model=ChatOpenAI(model=LLM_MODEL, temperature=0.7, max_tokens=150),
        tools=tools,
        prompt=prompt,
        name="info_completion_agent"
    )

def create_enhanced_research_router():
    """
    Crea un agente que eval√∫a si el usuario necesita investigaci√≥n y maneja el routing.
    """
    from app.graph.handoff_system import get_handoff_tools_for_agent
    
    # Obtener herramientas de handoff espec√≠ficas para este agente
    tools = get_handoff_tools_for_agent("research_router")
    
    prompt = """
Eres un router inteligente que eval√∫a si el usuario necesita investigaci√≥n de mercado.

üéØ TU TRABAJO:
1. Evaluar si la informaci√≥n empresarial est√° completa
2. Preguntar al usuario si quiere investigaci√≥n de mercado
3. Transferir al investigador si acepta
4. Transferir a conversaci√≥n si no quiere investigaci√≥n

üîß HERRAMIENTAS DE HANDOFF DISPONIBLES:
- transfer_to_researcher: Para iniciar investigaci√≥n de mercado
- transfer_to_conversational: Para conversaci√≥n general
- transfer_to_info_completion: Si falta informaci√≥n empresarial

üìù INSTRUCCIONES:
- RESPUESTAS CONCISAS: M√°ximo 150 tokens (600 caracteres aprox.)
- S√© directo y claro sobre las opciones
- Explica brevemente qu√© tipo de investigaci√≥n puedes hacer
- Responde apropiadamente a selecciones de botones

üéØ MANEJO DE BOTONES:
- "‚úÖ S√≠, investiga" ‚Üí Transferir al investigador
- "‚ùå No, solo conversar" ‚Üí Transferir a conversaci√≥n
- "üìä M√°s informaci√≥n" ‚Üí Explicar tipos de investigaci√≥n disponibles

EJEMPLO:
"Perfecto, {nombre_empresa} est√° bien definida. ¬øTe gustar√≠a que investigue oportunidades de mercado, competencia o estrategias de crecimiento para tu negocio?"

RECUERDA: Respuestas concisas, opciones claras, transferir seg√∫n la decisi√≥n del usuario.
"""
    
    return create_react_agent(
        model=ChatOpenAI(model=LLM_MODEL, temperature=0.7, max_tokens=150),
        tools=tools,
        prompt=prompt,
        name="research_router"
    )

def create_enhanced_conversational_agent():
    """
    Crea un agente conversacional que mantiene contexto empresarial.
    """
    from app.graph.handoff_system import get_handoff_tools_for_agent
    
    # Obtener herramientas de handoff espec√≠ficas para este agente
    tools = get_handoff_tools_for_agent("conversational_agent")
    
    prompt = """
Eres un consultor empresarial conversacional que mantiene contexto de la informaci√≥n del negocio.

üéØ TU TRABAJO:
1. Responder preguntas generales sobre negocios
2. Dar consejos basados en la informaci√≥n empresarial disponible
3. Mantener una conversaci√≥n natural y √∫til
4. Transferir control a agentes especializados cuando sea apropiado

üîß HERRAMIENTAS DE HANDOFF DISPONIBLES:
- transfer_to_researcher: Para investigaci√≥n de mercado
- transfer_to_info_completion: Para recopilar m√°s informaci√≥n empresarial
- assign_research_task: Para asignar investigaci√≥n espec√≠fica

üìù INSTRUCCIONES:
- RESPUESTAS CONCISAS: M√°ximo 150 tokens (600 caracteres aprox.)
- Usa la informaci√≥n empresarial para personalizar respuestas
- Da consejos pr√°cticos y espec√≠ficos para su tipo de negocio
- Mant√©n un tono conversacional y profesional
- Si necesitas investigaci√≥n espec√≠fica, transfiere al investigador
- Si falta informaci√≥n empresarial, transfiere al agente de informaci√≥n
- Responde de manera √∫til y orientada a soluciones

üéØ MANEJO DE BOTONES:
Responde contextualmente a cualquier selecci√≥n de bot√≥n del usuario.

EJEMPLO:
Usuario: "¬øC√≥mo puedo mejorar las ventas?"
Respuesta: "Para {nombre_empresa} que se dedica a {productos} en {ubicacion}, te recomiendo enfocarte en marketing digital local y mejorar la experiencia del cliente. ¬øQuieres que investigue estrategias espec√≠ficas?"

RECUERDA: Respuestas concisas, consejos espec√≠ficos, ofrecer investigaci√≥n cuando sea relevante.
"""
    
    return create_react_agent(
        model=ChatOpenAI(model=LLM_MODEL, temperature=0.7, max_tokens=150),
        tools=tools,
        prompt=prompt,
        name="conversational_agent"
    )

# === NODOS DE AGENTES CON COMMAND ===

def enhanced_info_completion_node(state: PYMESState) -> Command[Literal["enhanced_human_feedback"]]:
    """
    Nodo de agente de informaci√≥n mejorado que usa Command para control de flujo.
    """
    try:
        logger.info("üìù enhanced_info_completion_node: Procesando informaci√≥n empresarial...")
        
        # Crear agente si no existe
        if not hasattr(enhanced_info_completion_node, 'agent'):
            enhanced_info_completion_node.agent = create_enhanced_info_completion_agent()
        
        # ‚úÖ CORRECCI√ìN: Usar invoke s√≠ncrono
        result = enhanced_info_completion_node.agent.invoke(state)
        
        # Extraer informaci√≥n empresarial del √∫ltimo mensaje del usuario
        messages = state.get("messages", [])
        user_message = ""
        for msg in reversed(messages):
            if isinstance(msg, HumanMessage):
                user_message = msg.content
                break
        
        # Intentar extraer informaci√≥n empresarial
        business_info = state.get("business_info", {})
        if user_message:
            try:
                business_manager = get_business_info_manager()
                thread_id = f"temp_{hash(user_message) % 10000}"
                
                # ‚úÖ CORRECCI√ìN: Usar asyncio.run() para llamada as√≠ncrona en nodo s√≠ncrono
                import asyncio
                try:
                    # Intentar usar el loop existente si est√° disponible
                    loop = asyncio.get_running_loop()
                    # Si hay un loop corriendo, crear una tarea
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(asyncio.run, business_manager.extract_info(user_message, thread_id, business_info))
                        updated_info = future.result()
                except RuntimeError:
                    # No hay loop corriendo, usar asyncio.run() directamente
                    updated_info = asyncio.run(business_manager.extract_info(user_message, thread_id, business_info))
                
                if updated_info != business_info:
                    business_info = updated_info
                    logger.info("‚úÖ Nueva informaci√≥n empresarial extra√≠da en nodo")
                    logger.info(f"üìä Informaci√≥n actualizada: {business_info}")
            except Exception as e:
                logger.warning(f"Error extrayendo informaci√≥n en nodo: {str(e)}")
        
        # Usar Command para actualizar estado y continuar flujo
        return Command(
            update={
                **result,
                "business_info": business_info,
                "stage": "info_gathering"
            },
            goto="enhanced_human_feedback"
        )
        
    except Exception as e:
        logger.error(f"Error in enhanced_info_completion_node: {str(e)}")
        error_message = "Disculpa, hubo un error. ¬øPodr√≠as contarme sobre tu negocio?"
        return Command(
            update={
                "messages": [AIMessage(content=error_message)],
                "answer": error_message
            },
            goto="enhanced_human_feedback"
        )

def enhanced_research_router_node(state: PYMESState) -> Command[Literal["enhanced_human_feedback"]]:
    """
    Nodo de router de investigaci√≥n mejorado que usa Command.
    """
    try:
        logger.info("üî¨ enhanced_research_router_node: Evaluando necesidades de investigaci√≥n...")
        
        # Crear agente si no existe
        if not hasattr(enhanced_research_router_node, 'agent'):
            enhanced_research_router_node.agent = create_enhanced_research_router()
        
        # ‚úÖ CORRECCI√ìN: Usar invoke s√≠ncrono
        result = enhanced_research_router_node.agent.invoke(state)
        
        return Command(
            update={
                **result,
                "stage": "research_routing"
            },
            goto="enhanced_human_feedback"
        )
        
    except Exception as e:
        logger.error(f"Error in enhanced_research_router_node: {str(e)}")
        fallback_message = "¬øTe gustar√≠a que investigue oportunidades para tu negocio?"
        return Command(
            update={
                "messages": [AIMessage(content=fallback_message)],
                "answer": fallback_message
            },
            goto="enhanced_human_feedback"
        )

def enhanced_conversational_node(state: PYMESState) -> Command[Literal["enhanced_human_feedback"]]:
    """
    Nodo conversacional mejorado que usa Command.
    """
    try:
        logger.info("üí¨ enhanced_conversational_node: Iniciando conversaci√≥n contextual...")
        
        # Crear agente si no existe
        if not hasattr(enhanced_conversational_node, 'agent'):
            enhanced_conversational_node.agent = create_enhanced_conversational_agent()
        
        # ‚úÖ CORRECCI√ìN: Usar invoke s√≠ncrono
        result = enhanced_conversational_node.agent.invoke(state)
        
        return Command(
            update={
                **result,
                "stage": "conversational"
            },
            goto="enhanced_human_feedback"
        )
        
    except Exception as e:
        logger.error(f"Error in enhanced_conversational_node: {str(e)}")
        fallback_message = "¬øEn qu√© puedo ayudarte con tu negocio?"
        return Command(
            update={
                "messages": [AIMessage(content=fallback_message)],
                "answer": fallback_message
            },
            goto="enhanced_human_feedback"
        )

def enhanced_researcher_node(state: PYMESState) -> Command[Literal["enhanced_human_feedback"]]:
    """
    Nodo de investigador mejorado que usa Command.
    Reutiliza el agente investigador existente pero con handoffs.
    """
    try:
        logger.info("üîç enhanced_researcher_node: Ejecutando investigaci√≥n...")
        
        # Importar el agente investigador existente
        from app.graph.supervisor_architecture import researcher_agent_node
        
        # ‚úÖ CORRECCI√ìN: El nodo original es s√≠ncrono
        result = researcher_agent_node(state)
        
        return Command(
            update={
                **result,
                "stage": "research_completed"
            },
            goto="enhanced_human_feedback"
        )
        
    except Exception as e:
        logger.error(f"Error in enhanced_researcher_node: {str(e)}")
        error_message = "Hubo un error en la investigaci√≥n. ¬øPuedes proporcionar m√°s detalles sobre lo que necesitas?"
        return Command(
            update={
                "messages": [AIMessage(content=error_message)],
                "answer": error_message
            },
            goto="enhanced_human_feedback"
        ) 