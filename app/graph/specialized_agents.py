"""
Agentes especializados para el flujo de conversaci√≥n inteligente.
Implementa agentes que manejan diferentes aspectos de la conversaci√≥n empresarial.
"""

import logging
from typing import Dict, Any, List, Optional
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent

from app.config.settings import LLM_MODEL
from app.graph.state import PYMESState
from app.services.business_info_manager import get_business_info_manager

logger = logging.getLogger(__name__)

# === PROMPTS PARA AGENTES ESPECIALIZADOS ===

INFO_COMPLETION_PROMPT = """
Eres un asistente especializado en recopilar informaci√≥n empresarial de manera natural y conversacional.

TU TRABAJO:
1. Analizar la informaci√≥n empresarial ya disponible
2. Identificar qu√© informaci√≥n cr√≠tica falta
3. Hacer preguntas espec√≠ficas y naturales para completar la informaci√≥n
4. Extraer informaci√≥n de respuestas completas del usuario

INFORMACI√ìN ACTUAL:
{business_info}

CAMPOS FALTANTES CR√çTICOS:
{missing_fields}

CONTEXTO DE ROUTING:
{routing_context}

INSTRUCCIONES:
- Si faltan campos cr√≠ticos, haz UNA pregunta natural que pueda cubrir m√∫ltiples campos
- Si el usuario da informaci√≥n completa, extrae todo lo relevante
- S√© conversacional y no rob√≥tico (evita listas de preguntas)
- Reconoce y usa la informaci√≥n que ya tienes
- Si la informaci√≥n est√° completa, sugiere pasar a investigaci√≥n

CAMPOS CR√çTICOS M√çNIMOS:
- nombre_empresa: Nombre del negocio
- ubicacion: D√≥nde opera (ciudad, pa√≠s, online)
- productos_servicios_principales: Qu√© vende o ofrece
- descripcion_negocio: Descripci√≥n general del negocio

EJEMPLO DE CONVERSACI√ìN NATURAL:
‚ùå MAL: "¬øCu√°l es el nombre de tu empresa? ¬øD√≥nde est√° ubicada? ¬øQu√© productos vendes?"
‚úÖ BIEN: "¬°Hola! Me gustar√≠a ayudarte con tu negocio. Cu√©ntame un poco sobre tu empresa: ¬øc√≥mo se llama y qu√© tipo de productos o servicios ofreces?"

Responde de manera natural y conversacional.
"""

RESEARCH_ROUTER_PROMPT = """
Eres un asistente especializado en investigaci√≥n de mercado y oportunidades empresariales.

TU TRABAJO:
1. Evaluar si la informaci√≥n disponible es suficiente para investigaci√≥n
2. Consultar al usuario sobre qu√© tipo de investigaci√≥n necesita
3. Dirigir la conversaci√≥n hacia investigaci√≥n espec√≠fica
4. Mantener el contexto empresarial en toda la conversaci√≥n

INFORMACI√ìN EMPRESARIAL:
{business_info}

CONTEXTO DE ROUTING:
{routing_context}

ESTADO DE PREPARACI√ìN:
{research_readiness}

INSTRUCCIONES:
- Si la informaci√≥n es suficiente, pregunta qu√© tipo de investigaci√≥n necesita
- Ofrece opciones espec√≠ficas de investigaci√≥n basadas en su negocio
- Si necesita preguntar sobre investigaci√≥n, s√© espec√≠fico sobre qu√© puedes ofrecer
- Mant√©n el contexto empresarial en tus respuestas

TIPOS DE INVESTIGACI√ìN QUE PUEDES OFRECER:
1. An√°lisis de competencia en su sector
2. Oportunidades de mercado en su ubicaci√≥n
3. Tendencias de productos/servicios similares
4. Estrategias de crecimiento espec√≠ficas
5. An√°lisis de precios del mercado

EJEMPLO:
"Perfecto, {nombre_empresa}. Con la informaci√≥n de tu {descripcion_negocio} en {ubicacion}, puedo investigar varias oportunidades:

üîç ¬øTe interesa que analice tu competencia local?
üìä ¬øQuieres conocer tendencias del mercado de {productos}?
üìà ¬øTe gustar√≠a explorar nuevas oportunidades de crecimiento?

¬øQu√© tipo de investigaci√≥n te ser√≠a m√°s √∫til ahora?"

S√© espec√≠fico y orientado a acci√≥n.
"""

CONVERSATIONAL_PROMPT = """
Eres un consultor empresarial conversacional que mantiene contexto de la informaci√≥n del negocio.

TU TRABAJO:
1. Responder preguntas generales sobre negocios
2. Dar consejos basados en la informaci√≥n empresarial disponible
3. Mantener una conversaci√≥n natural y √∫til
4. Ofrecer orientaci√≥n pr√°ctica y espec√≠fica

INFORMACI√ìN EMPRESARIAL:
{business_info}

CONTEXTO DE LA CONVERSACI√ìN:
{conversation_context}

INSTRUCCIONES:
- Usa la informaci√≥n empresarial para personalizar tus respuestas
- Da consejos pr√°cticos y espec√≠ficos para su tipo de negocio
- Mant√©n un tono conversacional y profesional
- Si es relevante, sugiere investigaci√≥n o m√°s recopilaci√≥n de informaci√≥n
- Responde de manera √∫til y orientada a soluciones

EJEMPLO:
Usuario: "¬øC√≥mo puedo mejorar las ventas?"
Respuesta: "Para {nombre_empresa} que se dedica a {productos} en {ubicacion}, hay varias estrategias espec√≠ficas que podr√≠an funcionar bien..."

S√© √∫til, espec√≠fico y conversacional.
"""

# === AGENTES ESPECIALIZADOS ===

def info_completion_agent_node(state: PYMESState) -> Dict[str, Any]:
    """
    Agente especializado en completar informaci√≥n empresarial faltante.
    Maneja la recopilaci√≥n de informaci√≥n de manera natural y conversacional.
    """
    try:
        logger.info("üìù info_completion_agent_node: Analizando informaci√≥n faltante...")
        
        # Obtener informaci√≥n actual y contexto
        business_info = state.get("business_info", {})
        missing_fields = state.get("missing_fields", [])
        routing_context = state.get("routing_reason", "Recopilaci√≥n de informaci√≥n")
        change_mode = state.get("change_mode", False)
        
        # Primero, intentar extraer informaci√≥n del √∫ltimo mensaje del usuario
        messages = state.get("messages", [])
        user_message = ""
        for msg in reversed(messages):
            if isinstance(msg, HumanMessage):
                user_message = msg.content
                break
        
        # Si hay un mensaje del usuario, extraer informaci√≥n primero
        if user_message and len(messages) > 2:  # No es el primer mensaje
            logger.info("üîç Extrayendo informaci√≥n del mensaje del usuario...")
            business_manager = get_business_info_manager()
            thread_id = f"temp_{hash(user_message) % 10000}"
            
            try:
                updated_info = business_manager.extract_info(user_message, thread_id, business_info)
                if updated_info != business_info:
                    logger.info("‚úÖ Nueva informaci√≥n extra√≠da exitosamente")
                    business_info = updated_info
                    # Actualizar el estado con la nueva informaci√≥n
                    state["business_info"] = business_info
            except Exception as e:
                logger.warning(f"Error extrayendo informaci√≥n: {str(e)}")
        
        # Evaluar qu√© informaci√≥n sigue faltando
        critical_fields = ["nombre_empresa", "ubicacion", "productos_servicios_principales", "descripcion_negocio"]
        current_missing = [field for field in critical_fields if not business_info.get(field)]
        
        logger.info(f"üìä Informaci√≥n actual: {business_info}")
        logger.info(f"üìã Campos faltantes: {current_missing}")
        
        # Si ya no faltan campos cr√≠ticos, sugerir investigaci√≥n
        if not current_missing:
            logger.info("‚úÖ Informaci√≥n completa, sugiriendo investigaci√≥n")
            
            empresa = business_info.get("nombre_empresa", "tu empresa")
            productos = business_info.get("productos_servicios_principales", "tus productos/servicios")
            ubicacion = business_info.get("ubicacion", "tu ubicaci√≥n")
            
            completion_message = f"""¬°Excelente! üéâ Ya tengo toda la informaci√≥n b√°sica de {empresa}:

üìä **Resumen de tu negocio:**
üè¢ **Empresa:** {empresa}
üìç **Ubicaci√≥n:** {ubicacion}  
üì¶ **Productos/Servicios:** {productos}
üìã **Descripci√≥n:** {business_info.get("descripcion_negocio", "Informaci√≥n recopilada")}

Ahora que tengo el contexto completo de tu negocio, puedo ayudarte con:

üîç **Investigar oportunidades** de mercado espec√≠ficas para tu sector
üìà **Analizar la competencia** en tu zona
üí° **Sugerir estrategias** de crecimiento personalizadas

¬øTe gustar√≠a que comience con alg√∫n an√°lisis espec√≠fico, o tienes alguna pregunta particular sobre tu negocio?"""

            return {
                "messages": [AIMessage(content=completion_message)],
                "business_info": business_info,
                "answer": completion_message,
                "stage": "info_completed",
                "current_agent": "research_router"  # Sugerir cambio a research
            }
        
        # Si faltan campos, generar pregunta natural
        else:
            llm = ChatOpenAI(model=LLM_MODEL, temperature=0.7)  # M√°s creatividad para naturalidad
            
            prompt = ChatPromptTemplate.from_template(INFO_COMPLETION_PROMPT)
            
            response = llm.invoke(
                prompt.format(
                    business_info=business_info,
                    missing_fields=current_missing,
                    routing_context=routing_context
                )
            )
            
            question = response.content
            
            logger.info(f"‚ùì Pregunta generada: {question[:100]}...")
            
            return {
                "messages": [AIMessage(content=question)],
                "business_info": business_info,
                "answer": question,
                "missing_fields": current_missing,
                "stage": "info_gathering"
            }
            
    except Exception as e:
        logger.error(f"Error in info_completion_agent_node: {str(e)}")
        error_message = "Disculpa, hubo un error. ¬øPodr√≠as contarme sobre tu negocio?"
        return {
            "messages": [AIMessage(content=error_message)],
            "answer": error_message
        }

def research_router_node(state: PYMESState) -> Dict[str, Any]:
    """
    Agente que maneja el routing hacia investigaci√≥n y pregunta sobre intenciones de research.
    """
    try:
        logger.info("üî¨ research_router_node: Evaluando necesidades de investigaci√≥n...")
        
        business_info = state.get("business_info", {})
        routing_context = state.get("routing_reason", "Investigaci√≥n de mercado")
        should_ask_intent = state.get("should_ask_research_intent", False)
        research_readiness = state.get("research_readiness", 0.5)
        
        # Obtener √∫ltimo mensaje del usuario para detectar intenci√≥n
        messages = state.get("messages", [])
        user_message = ""
        for msg in reversed(messages):
            if isinstance(msg, HumanMessage):
                user_message = msg.content
                break
        
        # Detectar si el usuario menciona investigaci√≥n espec√≠fica
        research_keywords = ["investiga", "analiza", "oportunidades", "mercado", "competencia", "crecimiento", "estrategia"]
        wants_research = any(keyword in user_message.lower() for keyword in research_keywords)
        
        if wants_research:
            logger.info("üéØ Usuario quiere investigaci√≥n espec√≠fica")
            return {
                "current_agent": "researcher",
                "routing_reason": "Usuario solicit√≥ investigaci√≥n espec√≠fica",
                "stage": "research_requested"
            }
        
        # Si debe preguntar sobre intenci√≥n, crear mensaje consultivo
        llm = ChatOpenAI(model=LLM_MODEL, temperature=0.7)
        
        prompt = ChatPromptTemplate.from_template(RESEARCH_ROUTER_PROMPT)
        
        response = llm.invoke(
            prompt.format(
                business_info=business_info,
                routing_context=routing_context,
                research_readiness=f"{research_readiness:.1%}"
            )
        )
        
        router_message = response.content
        
        logger.info(f"ü§î Pregunta de routing generada: {router_message[:100]}...")
        
        return {
            "messages": [AIMessage(content=router_message)],
            "answer": router_message,
            "stage": "research_routing",
            "awaiting_research_decision": True
        }
        
    except Exception as e:
        logger.error(f"Error in research_router_node: {str(e)}")
        fallback_message = "¬øTe gustar√≠a que investigue oportunidades para tu negocio?"
        return {
            "messages": [AIMessage(content=fallback_message)],
            "answer": fallback_message
        }

def conversational_agent_node(state: PYMESState) -> Dict[str, Any]:
    """
    Agente conversacional que mantiene contexto empresarial.
    """
    try:
        logger.info("üí¨ conversational_agent_node: Iniciando conversaci√≥n contextual...")
        
        llm = ChatOpenAI(model=LLM_MODEL, temperature=0.7)
        
        # Obtener contexto empresarial
        business_info = state.get("business_info", {})
        
        # Crear contexto de conversaci√≥n
        messages = state.get("messages", [])
        recent_context = []
        for msg in messages[-4:]:  # √öltimos 4 mensajes
            if isinstance(msg, HumanMessage):
                recent_context.append(f"Usuario: {msg.content}")
            elif isinstance(msg, AIMessage):
                recent_context.append(f"Asistente: {msg.content}")
        
        conversation_context = "\n".join(recent_context)
        
        # Usar herramientas si es necesario (importar del m√≥dulo de nodos existente)
        try:
            from app.graph.nodes import search, search_documents
            tools = [search, search_documents]
            
            # Crear agente ReAct con contexto empresarial
            enhanced_prompt = CONVERSATIONAL_PROMPT + f"\n\nTOOLS DISPONIBLES: Puedes usar b√∫squeda web y de documentos si necesitas informaci√≥n espec√≠fica."
            
            agent = create_react_agent(llm, tools, prompt=enhanced_prompt)
            
            # Crear estado mejorado con contexto
            enhanced_state = {**state}
            enhanced_state["business_context"] = business_info
            enhanced_state["conversation_summary"] = conversation_context
            
            result = agent.invoke(enhanced_state)
            
            return {
                "messages": result["messages"],
                "stage": "conversational"
            }
            
        except ImportError:
            # Fallback sin herramientas
            prompt = ChatPromptTemplate.from_template(CONVERSATIONAL_PROMPT)
            
            response = llm.invoke(
                prompt.format(
                    business_info=business_info,
                    conversation_context=conversation_context
                )
            )
            
            return {
                "messages": [AIMessage(content=response.content)],
                "answer": response.content,
                "stage": "conversational"
            }
            
    except Exception as e:
        logger.error(f"Error in conversational_agent_node: {str(e)}")
        fallback_message = "¬øEn qu√© puedo ayudarte con tu negocio?"
        return {
            "messages": [AIMessage(content=fallback_message)],
            "answer": fallback_message
        } 