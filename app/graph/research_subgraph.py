import logging
from typing import Dict, Any, List
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_community.tools import TavilySearchResults
from langgraph.graph import StateGraph, START, END
from langgraph.types import Command

from app.config.settings import LLM_MODEL
from app.graph.state import PYMESState

logger = logging.getLogger(__name__)

# Prompt para investigaciÃ³n de oportunidades
RESEARCH_OPPORTUNITIES_PROMPT = """
Eres un consultor experto en PYMES especializado en identificar oportunidades de crecimiento y mejora.

INFORMACIÃ“N DEL NEGOCIO:
{business_info}

INSTRUCCIONES:
1. Analiza la informaciÃ³n del negocio proporcionada
2. Identifica Ã¡reas clave de oportunidad basadas en:
   - Sector y mercado actual
   - DesafÃ­os identificados
   - UbicaciÃ³n y alcance
   - Productos/servicios actuales

3. Genera bÃºsquedas especÃ­ficas para investigar:
   - Tendencias del sector
   - Mejores prÃ¡cticas de la industria
   - Oportunidades de mercado
   - Soluciones a los desafÃ­os identificados
   - Casos de Ã©xito similares

FORMATO DE RESPUESTA:
Devuelve una lista de consultas de bÃºsqueda especÃ­ficas, una por lÃ­nea, que permitan investigar oportunidades relevantes.

Ejemplo:
- Tendencias 2024 sector restaurantes Lima PerÃº
- Mejores prÃ¡cticas marketing digital restaurantes pequeÃ±os
- Oportunidades delivery comida Lima mercado
- Soluciones problemas personal restaurantes PYMES

"""

ANALYSIS_PROMPT = """
Eres un consultor de PYMES experto en anÃ¡lisis de oportunidades de crecimiento.

INFORMACIÃ“N DEL NEGOCIO:
{business_info}

RESULTADOS DE INVESTIGACIÃ“N:
{research_results}

INSTRUCCIONES:
BasÃ¡ndote en la informaciÃ³n del negocio y los resultados de la investigaciÃ³n, genera un anÃ¡lisis completo que incluya:

1. **OPORTUNIDADES IDENTIFICADAS**: Lista las principales oportunidades de crecimiento encontradas
2. **TENDENCIAS RELEVANTES**: Tendencias del sector que pueden aprovechar
3. **MEJORES PRÃCTICAS**: PrÃ¡cticas exitosas que pueden implementar
4. **SOLUCIONES A DESAFÃOS**: Soluciones especÃ­ficas para los desafÃ­os mencionados
5. **RECOMENDACIONES PRIORITARIAS**: 3-5 recomendaciones principales ordenadas por impacto

SÃ© especÃ­fico y prÃ¡ctico. Todas las recomendaciones deben ser aplicables al contexto especÃ­fico del negocio.
"""


class ResearchAgent:
    """Agente de investigaciÃ³n para PYMES."""
    
    def __init__(self):
        self.llm = ChatOpenAI(model=LLM_MODEL, temperature=0.1)
        self.search_tool = TavilySearchResults(max_results=3)
    
    def generate_search_queries(self, business_info: Dict[str, Any]) -> List[str]:
        """Genera consultas de bÃºsqueda especÃ­ficas basadas en la informaciÃ³n del negocio."""
        try:
            prompt = ChatPromptTemplate.from_template(RESEARCH_OPPORTUNITIES_PROMPT)
            chain = prompt | self.llm
            
            response = chain.invoke({"business_info": str(business_info)})
            
            # Extraer las consultas del resultado
            queries = []
            for line in response.content.split('\n'):
                line = line.strip()
                if line and (line.startswith('-') or line.startswith('â€¢')):
                    query = line.lstrip('-â€¢ ').strip()
                    if query:
                        queries.append(query)
            
            logger.info(f"Generadas {len(queries)} consultas de bÃºsqueda")
            return queries[:5]  # Limitar a 5 bÃºsquedas para no sobrecargar
            
        except Exception as e:
            logger.error(f"Error generando consultas de bÃºsqueda: {str(e)}")
            return [
                f"oportunidades crecimiento {business_info.get('sector', 'negocio')} {business_info.get('ubicacion', 'Peru')}",
                f"tendencias {business_info.get('sector', 'industria')} 2024",
                f"mejores prÃ¡cticas PYMES {business_info.get('sector', 'pequeÃ±os negocios')}"
            ]
    
    def search_opportunities(self, queries: List[str]) -> List[Dict[str, str]]:
        """Realiza bÃºsquedas web para cada consulta."""
        all_results = []
        
        for query in queries:
            try:
                logger.info(f"Buscando: {query}")
                results = self.search_tool.invoke(query)
                
                for result in results:
                    if isinstance(result, dict):
                        all_results.append({
                            "query": query,
                            "content": result.get("content", ""),
                            "url": result.get("url", ""),
                            "title": result.get("title", "")
                        })
                
            except Exception as e:
                logger.error(f"Error en bÃºsqueda '{query}': {str(e)}")
                continue
        
        logger.info(f"Recopilados {len(all_results)} resultados de investigaciÃ³n")
        return all_results
    
    def analyze_opportunities(self, business_info: Dict[str, Any], research_results: List[Dict[str, str]]) -> str:
        """Analiza los resultados y genera recomendaciones."""
        try:
            # Formatear los resultados de investigaciÃ³n
            formatted_results = []
            for result in research_results:
                formatted_results.append(
                    f"**BÃºsqueda**: {result['query']}\n"
                    f"**Fuente**: {result.get('title', 'N/A')}\n"
                    f"**Contenido**: {result['content']}\n"
                    f"**URL**: {result.get('url', 'N/A')}\n"
                )
            
            research_text = "\n---\n".join(formatted_results)
            
            prompt = ChatPromptTemplate.from_template(ANALYSIS_PROMPT)
            chain = prompt | self.llm
            
            response = chain.invoke({
                "business_info": str(business_info),
                "research_results": research_text
            })
            
            return response.content
            
        except Exception as e:
            logger.error(f"Error en anÃ¡lisis de oportunidades: {str(e)}")
            return "Hubo un error analizando las oportunidades encontradas."


def research_opportunities_node(state: PYMESState) -> Dict[str, Any]:
    """
    Nodo principal de investigaciÃ³n de oportunidades.
    """
    try:
        logger.info("Iniciando investigaciÃ³n de oportunidades")
        
        business_info = state.get("business_info", {})
        if not business_info:
            logger.warning("No hay informaciÃ³n del negocio disponible para investigar")
            return {
                "messages": [AIMessage(content="No tengo informaciÃ³n suficiente del negocio para realizar la investigaciÃ³n.")],
                "stage": "error"
            }
        
        research_agent = ResearchAgent()
        
        # Generar consultas de bÃºsqueda
        queries = research_agent.generate_search_queries(business_info)
        logger.info(f"Consultas generadas: {queries}")
        
        # Realizar bÃºsquedas
        research_results = research_agent.search_opportunities(queries)
        
        # Analizar resultados
        analysis = research_agent.analyze_opportunities(business_info, research_results)
        
        return {
            "web_search": f"InvestigaciÃ³n completada con {len(research_results)} resultados",
            "context": analysis,
            "stage": "research_completed",
            "messages": [AIMessage(content=f"ğŸ” **INVESTIGACIÃ“N COMPLETADA**\n\nHe analizado las oportunidades para tu negocio **{business_info.get('nombre_empresa', 'N/A')}**.\n\n{analysis}")]
        }
        
    except Exception as e:
        logger.error(f"Error en research_opportunities_node: {str(e)}")
        return {
            "messages": [AIMessage(content="Hubo un error durante la investigaciÃ³n. IntentarÃ© nuevamente.")],
            "stage": "error"
        }


def validate_research_results_node(state: PYMESState) -> Command:
    """
    Valida los resultados de investigaciÃ³n con el usuario.
    """
    try:
        logger.info("Validando resultados de investigaciÃ³n")
        
        context = state.get("context", "")
        business_info = state.get("business_info", {})
        
        validation_message = f"""
ğŸ¯ **ANÃLISIS DE OPORTUNIDADES COMPLETADO**

He investigado oportunidades especÃ­ficas para **{business_info.get('nombre_empresa', 'tu negocio')}** y encontrÃ© informaciÃ³n muy relevante.

{context}

ğŸ“‹ **Â¿Te gustarÃ­a que desarrolle un plan de acciÃ³n detallado basado en estas oportunidades?**

Responde:
- âœ… **"SÃ"** para generar un plan de acciÃ³n completo
- ğŸ”„ **"MÃS INFORMACIÃ“N"** si necesitas investigaciÃ³n adicional sobre algÃºn punto especÃ­fico
- ğŸ’¬ **"PREGUNTAS"** si tienes dudas sobre alguna recomendaciÃ³n

*TambiÃ©n puedes hacer preguntas especÃ­ficas sobre cualquier oportunidad mencionada.*
"""

        from langgraph.types import interrupt
        user_response = interrupt({
            "message": validation_message,
            "context": context,
            "stage": "research_validation"
        })
        
        logger.info(f"Respuesta del usuario: {user_response}")
        
        response_lower = user_response.lower().strip()
        
        if response_lower in ["sÃ­", "si", "yes", "generar plan", "plan de acciÃ³n"]:
            return Command(
                update={
                    "stage": "plan_generation",
                    "messages": [HumanMessage(content=user_response)]
                },
                goto="generate_growth_plan"
            )
        
        elif "mÃ¡s informaciÃ³n" in response_lower or "investigaciÃ³n" in response_lower:
            return Command(
                update={
                    "messages": [HumanMessage(content=user_response)]
                },
                goto="research_opportunities"
            )
        
        else:
            # Respuesta general o pregunta - continuar conversaciÃ³n
            return Command(
                update={
                    "input": user_response,
                    "messages": [HumanMessage(content=user_response)],
                    "stage": "conversation"
                },
                goto="generate_response"  # Ir al nodo de conversaciÃ³n general
            )
            
    except Exception as e:
        logger.error(f"Error en validate_research_results_node: {str(e)}")
        return Command(
            update={
                "messages": [AIMessage(content="Hubo un error validando los resultados. Â¿PodrÃ­as repetir tu respuesta?")]
            },
            goto="validate_research_results"
        )


def create_research_subgraph():
    """
    Crea el sub-grafo de investigaciÃ³n de oportunidades.
    """
    try:
        # Crear el grafo
        workflow = StateGraph(PYMESState)
        
        # Agregar nodos
        workflow.add_node("research_opportunities", research_opportunities_node)
        workflow.add_node("validate_research_results", validate_research_results_node)
        
        # Definir flujo
        workflow.add_edge(START, "research_opportunities")
        workflow.add_edge("research_opportunities", "validate_research_results")
        workflow.add_edge("validate_research_results", END)
        
        logger.info("Sub-grafo de investigaciÃ³n creado exitosamente")
        return workflow.compile()
        
    except Exception as e:
        logger.error(f"Error creando sub-grafo de investigaciÃ³n: {str(e)}")
        raise 